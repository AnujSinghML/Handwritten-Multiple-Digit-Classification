A further update in the handwritten digit classification project.
This time we use ReLU activation layer and use softmax in the output layer while compiling.
Thus we can predict multiple digits from 0-9 unlike the last project where we only only predicted binary digits.
The data for model training and prediction to check accuracy is in X.npy and y.npy - which is a subset of the MNIST handwritten digit dataset (http://yann.lecun.com/exdb/mnist/).
Comments in the code , explain everything.

